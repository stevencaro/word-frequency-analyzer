#!/usr/bin/python3

from itertools import zip_longest

import argparse
import sys

class WordList():

    def __init__(self):
        self.word_list = {}

        with open('/home/scaro/git/word-frequency-analyzer/top-500-words') as f:
            for line in f.readlines():
                line = line.strip()
                self.word_list[line] = 0

        with open('/home/scaro/git/word-frequency-analyzer/top-100-verbs-with-conjugation') as f:
            for line in f.readlines():
                words = line.split()
                for word in words:
                    self.word_list[word] = 0

# The following is a recipe from the itertools documentation page:
# https://docs.python.org/3/library/itertools.html
def grouper(iterable, n, fillvalue=None):
    "Collect data into fixed-length chunks or blocks"
    args = [iter(iterable)] * n
    return zip_longest(*args, fillvalue=fillvalue)

if __name__ == '__main__':

    # Process command line arguments
    parser = argparse.ArgumentParser(description='Show count of frequent words in given text')
    parser.add_argument('text_file', nargs='?', default=None, help='text to process')
    parser.add_argument('-i', dest = 'show_infrequent', action='store_true',  help='Show infrequent words in text')
    parser.add_argument('-f', dest = 'show_frequent', action='store_true',  help='Show frequent words in text')
    parser.add_argument('-wl', dest = 'show_word_list', action='store_true',  help='Show words in frequent word list and exit.')

    #group = parser.add_mutually_exclusive_group()
    #group.add_argument('text_file', help='text to process')
    #group.add_argument('-wl', dest = 'show_word_list', action='store_true',  help='Show words in frequent word list and exit.')

    args = parser.parse_args()
    content_file = args.text_file

    if args.show_word_list or content_file == None:
        sys.exit()

    # The following code reads the content as one chunk of data:
    with open(content_file) as f:
        content = f.read()

    # The following code strips double quotes, single quotes, commas, periods, colons
    # and parentheses from the ends of each word in the content:
    content_words          = [ word.lower().lstrip('(“"‘\'').rstrip('):,."”\'’') \
                             for word in content.split() ]

    # Calculates total word count and unique words in the content:
    count_of_total_words = len(content_words)
    content_unique_words = set(content_words)

    # Creates the frequent word word-list:
    wl = WordList()

    infrequent_words = []
    # Calculates which words in the content are in the frequent words dictionary
    for word in sorted(content_unique_words):
        if word in wl.word_list:
           wl.word_list[word] += 1
        else:
            infrequent_words.append(word)

    frequent_words   = []
    # Collects the words that were calculated to be frequent
    for word in sorted(wl.word_list):
        if wl.word_list[word] > 0:
            frequent_words.append(word)

    # Calculates and displays the totals:
    count_of_unique_words     = len(content_unique_words)
    count_of_frequent_words   = len(frequent_words)
    count_of_infrequent_words = len(infrequent_words)

    print (count_of_total_words, "total words")
    print (count_of_unique_words, "unique words")
    print (count_of_frequent_words, "frequent words")

    if args.show_frequent:
    # Prints the frequent words in a 5 column format
        for wds in grouper(frequent_words, 5, fillvalue = ""):
            print('  {:15.15} {:15.15} {:15.15} {:15.15} {:15.15}'.format(*wds))

    print (count_of_infrequent_words, "infrequent words" )

    if args.show_infrequent:
        # Prints the infrequent words in a 5 column format
        for wds in grouper(infrequent_words, 5, fillvalue = ""):
            print('  {:15.15} {:15.15} {:15.15} {:15.15} {:15.15}'.format(*wds))

    # Prints the percentages of frequent words and infrequent words
    print('Percentage frequent words: {:.2%} '.format( count_of_frequent_words / count_of_unique_words))
    print('Percentage infrequent words: {:.2%} '.format( count_of_infrequent_words / count_of_unique_words))
