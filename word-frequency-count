#!/usr/bin/python3

from itertools import zip_longest
from math import ceil

import argparse
import sys

class WordList():

    def __init__(self):
        self.word_list = {}

        with open('/home/scaro/git/word-frequency-analyzer/top-500-words') as f:
            for line in f.readlines():
                line = line.strip()
                self.word_list[line] = 0

        with open('/home/scaro/git/word-frequency-analyzer/top-100-verbs-with-conjugation') as f:
            for line in f.readlines():
                words = line.split()
                for word in words:
                    self.word_list[word] = 0

# The following is a recipe from the itertools documentation page:
# https://docs.python.org/3/library/itertools.html
def grouper(iterable, n, fillvalue=None):
    "Collect data into fixed-length chunks or blocks"
    args = [iter(iterable)] * n
    return zip_longest(*args, fillvalue=fillvalue)

if __name__ == '__main__':

    # Process command line arguments
    parser = argparse.ArgumentParser(description='Show count of frequent words in given text')
    parser.add_argument('text_file', nargs='?', default=None, help='text to process')
    parser.add_argument('-i', dest = 'show_infrequent', action='store_true',  help='Show infrequent words in text')
    parser.add_argument('-f', dest = 'show_frequent', action='store_true',  help='Show frequent words in text')
    parser.add_argument('-wl', dest = 'show_word_list', action='store_true',  help='Show words in frequent word list and exit.')

    args = parser.parse_args()
    content_file = args.text_file

    if args.show_word_list or content_file == None:
        sys.exit()

    # The following code reads the content as one chunk of data:
    with open(content_file) as f:
        content = f.read()

    # The following code strips double quotes, single quotes, commas, periods, colons
    # and parentheses from the ends of each word in the content:
    content_words          = [ word.lower().lstrip('(“"‘\'').rstrip('):,."”\'’') \
                             for word in content.split() ]

    # Calculates total word count and unique words in the content:
    count_of_total_words = len(content_words)
    content_unique_words = set(content_words)

    # Creates the frequent word word-list:
    wl = WordList()

    infrequent_words = []
    # Calculates which words in the content are in the frequent words dictionary
    for word in sorted(content_unique_words):
        if word in wl.word_list:
           wl.word_list[word] += 1
        else:
            infrequent_words.append(word)

    frequent_words   = []
    # Collects the words that were calculated to be frequent
    for word in sorted(wl.word_list):
        if wl.word_list[word] > 0:
            frequent_words.append(word)

    # Calculates and displays the totals:
    count_of_unique_words     = len(content_unique_words)
    count_of_frequent_words   = len(frequent_words)
    count_of_infrequent_words = len(infrequent_words)

    print (count_of_total_words, "total words")
    print (count_of_unique_words, "unique words")
    print (count_of_frequent_words, "frequent words")

    def pad_short_word_list(word_list_to_pad, num_columns_in_output):
        len_word_list = len(word_list_to_pad)
        padding = num_columns_in_output - len_word_list

        padded_word_list = word_list_to_pad.extend(['--'] * padding)
        print(padded_word_list)
        return padded_word_list

    def display_words(word_list):
        # Displays words in a 5 column format
        #print(type(word_list))
        NUM_COLUMNS = 5
        num_words_per_column = ceil(len(word_list) / NUM_COLUMNS )

        if len(word_list) < NUM_COLUMNS:
            #word_list = pad_short_word_list(word_list, NUM_COLUMNS)
            #print(type(word_list))
            for word in word_list:
                print ('\t', word, end=' ')
            print()
            return

        def fill_columns(word_list_inner):
            return list(grouper(word_list_inner, num_words_per_column, '--'))

        (col1, col2, col3, col4, col5) = fill_columns(word_list)

        for wds in zip_longest(col1, col2, col3, col4, col5):
            print('  {:15.15} {:15.15} {:15.15} {:15.15} {:15.15}'.format(*wds))

    if args.show_frequent:
        display_words(frequent_words)

    print (count_of_infrequent_words, "infrequent words" )
    if args.show_infrequent:
        display_words(infrequent_words)

    # Prints the percentages of frequent words and infrequent words
    print('Percentage frequent words: {:.2%} '.format( count_of_frequent_words / count_of_unique_words))
    print('Percentage infrequent words: {:.2%} '.format( count_of_infrequent_words / count_of_unique_words))

