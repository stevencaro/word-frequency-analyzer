#!/usr/bin/python3

from itertools import zip_longest
from math import ceil

import argparse
import sys

class WordList():

    def __init__(self):
        self.word_list = {}

        with open('/home/scaro/git/word-frequency-analyzer/top-500-words') as f:
            for line in f.readlines():
                line = line.strip()
                self.word_list[line] = 0

        with open('/home/scaro/git/word-frequency-analyzer/top-100-verbs-with-conjugation') as f:
            for line in f.readlines():
                words = line.split()
                for word in words:
                    self.word_list[word] = 0

# The following is a recipe from the itertools documentation page:
#   https://docs.python.org/3/library/itertools.html
# I use it to group the output into columns
def grouper(iterable, n, fillvalue=None):
    # Collect data into fixed-length chunks or blocks
    args = [iter(iterable)] * n
    return zip_longest(*args, fillvalue=fillvalue)

def display_words(word_list):
    # This function displays the words in word_list in a 5 column format
    # It provides a useful contrast in programming style to the class that
    # follows, which performs the same function, but is more customizable
    NUM_COLUMNS = 5
    num_words_per_column = ceil(len(word_list) / NUM_COLUMNS )

    # Handles very short lists with fewer than 5 words:
    if len(word_list) < NUM_COLUMNS:
        for word in word_list:
            print ('    ', word, end=' ')
        print()
        return

    # Fills five lists, one for each column of the output:
    (col1, col2, col3, col4, col5) = \
            list(grouper(word_list, num_words_per_column, '--'))

    # displays each column of the output, one row at a time:
    for wds in zip_longest(col1, col2, col3, col4, col5):
        print('  {:15.15} {:15.15} {:15.15} {:15.15} {:15.15}'.format(*wds))


class ListToSortedColumns():
    # This class generalizes the display_words() function
    def __init__(self, data, num_columns, fill='--'):

        self._list = sorted(data)
        self._num_cols = num_columns
        self._num_words_per_column = ceil(len(self._list) / self._num_cols )
        self._fill = fill

        self.cols = list( grouper(self._list, self._num_words_per_column, fill))
        self.rows = zip_longest(*self.cols, fillvalue=fill)

    def display(self, width=15, truncate=15):
        # Creates the format {:15.15}:
        word_fmt = '{{:{}.{}}}'.format(width, truncate)

        # And then repeats it for the number of columns
        col_fmt = word_fmt * self._num_cols
        # Prints the data. Will raise an IndexError on small data sets
        # with fewer than _num_cols words
        try:
            for row in self.rows:
                print(col_fmt.format(*row))
        except IndexError:
            num_cols = len(row)
            col_fmt_b = word_fmt * num_cols
            print(col_fmt_b.format(*row))


if __name__ == '__main__':

    # Process command line arguments
    parser = argparse.ArgumentParser(description='Show count of frequent words in given text')
    parser.add_argument('text_file', nargs='?', default=None, help='text to process')
    parser.add_argument('-i', dest = 'show_infrequent',
                        action = 'store_true',  help='Show infrequent words in text')
    parser.add_argument('-f', dest = 'show_frequent',
                        action = 'store_true',  help='Show frequent words in text')
    parser.add_argument('-wl', dest = 'show_word_list',
                        action = 'store_true',  help='Show words in frequent word list and exit.')

    args = parser.parse_args()
    content_file = args.text_file

    if args.show_word_list or content_file == None:
        sys.exit()

    # Reads the content as one chunk of data:
    with open(content_file) as f:
        content = f.read()

    # Strips double quotes, single quotes, commas, periods, colons
    # and parentheses from the ends of each word in the content:
    content_words = [ word.lower().
                      lstrip('(“"‘\'').
                      rstrip('):,."”\'’') \
                      for word in content.split() ]

    # Calculates total word count and unique words in the content:
    count_of_total_words = len(content_words)
    content_unique_words = set(content_words)

    # Creates the frequent word word-list:
    wl = WordList()

    # Creates the lists to store the results:
    infrequent_words = []
    frequent_words   = []

    # Calculates which words in the content are in the frequent words dictionary
    for word in sorted(content_unique_words):
        if word in wl.word_list:
           wl.word_list[word] += 1
        else:
            infrequent_words.append(word)

    # Collects the words that were calculated to be frequent
    for word in sorted(wl.word_list):
        if wl.word_list[word] > 0:
            frequent_words.append(word)

    # Calculates the totals:
    count_of_unique_words     = len(content_unique_words)
    count_of_frequent_words   = len(frequent_words)
    count_of_infrequent_words = len(infrequent_words)

    # Displays the results:
    print (count_of_total_words, "total words")
    print (count_of_unique_words, "unique words")
    print (count_of_frequent_words, "frequent words")

    NUM_COLUMNS = 5
    if args.show_frequent:
        output = ListToSortedColumns(frequent_words, NUM_COLUMNS)
        output.display()

    print (count_of_infrequent_words, "infrequent words" )

    if args.show_infrequent:
        output = ListToSortedColumns(infrequent_words, NUM_COLUMNS)
        output.display()

    # Prints the percentages of frequent words and infrequent words
    print('Percentage frequent words: {:.2%} '\
          .format( count_of_frequent_words / count_of_unique_words))

    print('Percentage infrequent words: {:.2%} '\
          .format( count_of_infrequent_words / count_of_unique_words))

